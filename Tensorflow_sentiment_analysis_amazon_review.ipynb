{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow sentiment analysis amazon review",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqJp5kU0IUfuUD6vyMc/QS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jawaluke/DL-NLP-natural-language-processing-/blob/master/Tensorflow_sentiment_analysis_amazon_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW2gjt1c7EfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# enabling the gpu\n",
        "# install dependencies\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xmxPE7Is4z5",
        "colab_type": "text"
      },
      "source": [
        "# **AMAZON reviews to classify positive / negative reviews**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AWcc4RWs2HN",
        "colab_type": "text"
      },
      "source": [
        "#**Using Tensorflow and Keras for the NLP classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFi75x8QszVB",
        "colab_type": "text"
      },
      "source": [
        "#**First enabling the GPU and check our gpu property by the below code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3N4adWH-SIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESYzn5E7-cMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checking the version\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEbpRdBl0H8W",
        "colab_type": "text"
      },
      "source": [
        "#**Loading the dataset from the Tensorflow datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N28VBbd5_MGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading the datasets\n",
        "\n",
        "datasets, info = tfds.load(\"amazon_us_reviews/Mobile_Electronics_v1_00\", with_info= True)\n",
        " \n",
        "# train datasets\n",
        "\n",
        "train_data = datasets[\"train\"]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVBDCJut0aw7",
        "colab_type": "text"
      },
      "source": [
        "info - the information about the dataset (dataset exploring)\n",
        "\n",
        "train - full dataset without split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XokXVdwJ1Cem",
        "colab_type": "text"
      },
      "source": [
        "if you run the below code\n",
        " you will see the dataset info and it contain every detail of the amazon's \n",
        "product\n",
        "\n",
        "but, we need only reviews text and rating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3wRLcFtADVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# info of the datasets\n",
        "\n",
        "info\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvNzACtr1m09",
        "colab_type": "text"
      },
      "source": [
        " we are gonna take the review and star rating see the customer reviews\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5Nrf-T7Arr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we are gonna take the review and star rating see the customer reviews\n",
        "\n",
        "print(train_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXDAgdtWB5f-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# length of the datasets\n",
        "\n",
        "len(list(train_data))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FYKligoCDBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting the batch size and buffer size\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 30000\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF5VLVk_1w1z",
        "colab_type": "text"
      },
      "source": [
        "#**Shuffle the datasets**\n",
        "\n",
        "we don't need it to be ordered"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPuOo3lHClCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting the data shuffle\n",
        "\n",
        "train_data = train_data.shuffle(BUFFER_SIZE, reshuffle_each_iteration= False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQUXE-Oo2F0w",
        "colab_type": "text"
      },
      "source": [
        " in tensorflow you need to iterate things to display ,for example\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAOpw5rzDM0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# in tensorflow you need to iterate things to show for example\n",
        "\n",
        "for reviews in train_data.take(2):\n",
        "  print(reviews)\n",
        "# all were in tensor shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr7OWnLL2TB5",
        "colab_type": "text"
      },
      "source": [
        "Extracting only the reviews text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClvuNWSLDpS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for reviews in train_data.take(4):\n",
        "  # printing the reviews of people by iterating the tensorflow just like a json format\n",
        "\n",
        "  print(reviews[\"data\"][\"review_body\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4wkh3_e2rH-",
        "colab_type": "text"
      },
      "source": [
        "To remove tensor shape use numpy()\n",
        "\n",
        "Basically we are doing here is. showing the review texts and coorespondent rating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o5vek953cIM",
        "colab_type": "text"
      },
      "source": [
        "ratings like in range(1-5) but we want it to be 0 and 1\n",
        "\n",
        "by making threshold as a 3 \n",
        "\n",
        "0 - negative reviews  ( < 3 )\n",
        "\n",
        "1 - positive reviews  ( > 3)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V21qWEBFFT1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now making the rating with some threshold like positive and negative ( 0 and 1 )\n",
        "\n",
        "for reviews in train_data.take(5):\n",
        "  print(reviews[\"data\"].get(\"review_body\").numpy())\n",
        "  \n",
        "  print(reviews[\"data\"].get(\"star_rating\"))\n",
        "\n",
        "  # here we are making the condition like 0 and 1\n",
        "\n",
        "  print(tf.where(reviews[\"data\"].get(\"star_rating\")>3,1,0).numpy())\n",
        "\n",
        "  print(\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doMo8llc3XX0",
        "colab_type": "text"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIGE-VQk3XCm",
        "colab_type": "text"
      },
      "source": [
        "going to tokenize the words in this review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj13WMoRGtsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now tokenizing\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UmizydWHb-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# considering the vocab_size\n",
        "\n",
        "vocab_size = 73738"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MlnFH3g5AMI",
        "colab_type": "text"
      },
      "source": [
        "creating a sentences and label list and appending the reviews texts and rating\n",
        "\n",
        "sentences ----> reviews text\n",
        "\n",
        "labels -------> ratings( 0 and 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6Vl33-8JEh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sep_text_reviews(train_data):\n",
        "  sentences = []\n",
        "  labels = []\n",
        "  for reviews in train_data:\n",
        "    sentences.append(reviews[\"data\"].get(\"review_body\").numpy().decode(\"utf-8\"))\n",
        "    labels.append(tf.where(reviews[\"data\"].get(\"star_rating\")>3,1,0).numpy())\n",
        "  return sentences, labels\n",
        "\n",
        "# call the function\n",
        "\n",
        "sentences, labels = sep_text_reviews(train_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHOCxh4dP662",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68iXxBIkQztp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVMl4Rnw5haV",
        "colab_type": "text"
      },
      "source": [
        "now all the reviews and ratings are stored in a list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F38HQt4gQ9UR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,3):\n",
        "  print(sentences[i])\n",
        "  print(labels[i])\n",
        "  print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMJ05eIS5t6q",
        "colab_type": "text"
      },
      "source": [
        "#**Train and Test split**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzhdkjuK54fq",
        "colab_type": "text"
      },
      "source": [
        "from the length of datasset were 104975\n",
        "\n",
        "splitting into , \n",
        "\n",
        "training ---> 85000\n",
        "\n",
        "testing ----> 104975 - 85000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aioPpz1WRBFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "training_size = 85000\n",
        "\n",
        "training_data =  np.array(sentences[0:training_size])\n",
        "training_labels = np.array(labels[0:training_size])\n",
        "\n",
        "testing_data = np.array(sentences[training_size:])\n",
        "testing_labels = np.array(labels[training_size:])\n",
        "\n",
        "training_data.shape , training_labels.shape, testing_data.shape, testing_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF_j3xYr6cvF",
        "colab_type": "text"
      },
      "source": [
        "Tokenizing the reviews into tokenize word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KUJ3W50WOl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words= 73738 , oov_token= \"<OOV>\")\n",
        "tokenizer.fit_on_texts(training_data)\n",
        "\n",
        "word_index = tokenizer.word_index\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsLkH35Z6pvt",
        "colab_type": "text"
      },
      "source": [
        "From the below code,\n",
        "\n",
        "as you see the reviews text words are numbered "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvcCokJhZWng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index.items()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-oCO7Xy6899",
        "colab_type": "text"
      },
      "source": [
        "based on the sentences we are using the numbered reviews words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRz2iFiAZbyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_sequences = tokenizer.texts_to_sequences(training_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuPc8ew1etX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "training_sequences[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT0TB2U27QDT",
        "colab_type": "text"
      },
      "source": [
        "we need a maximum length of the reviews overall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsAuo-iOewZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_sequence_len = max([len(x) for x in training_sequences])\n",
        "max_sequence_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jVog9Yw7d9X",
        "colab_type": "text"
      },
      "source": [
        "padding is convert our sentences with the maximum length of reviews \n",
        "\n",
        "eg:\n",
        " \n",
        " our reviews maximum length is 2943\n",
        "\n",
        " so, converting every sentence with that maximum length by adding 0 in front"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dtWGFIBfaX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_padded = pad_sequences( training_sequences, maxlen= max_sequence_len, truncating = \"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbt9MIjYfs6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_padded[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMaq9OWQ8KNi",
        "colab_type": "text"
      },
      "source": [
        "Similar way with the testing sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5hl2bBmfvSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_sequences = tokenizer.texts_to_sequences(testing_data)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen= max_sequence_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PO2p9y18Upe",
        "colab_type": "text"
      },
      "source": [
        "#**Define our model**\n",
        "\n",
        "- we are using bidirectional LSTM for our model [link for the Documentation](https://keras.io/api/layers/recurrent_layers/lstm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoS-h_9_hUkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model define\n",
        "\n",
        "\n",
        "model = keras.Sequential([\n",
        "                          \n",
        "keras.layers.Embedding(vocab_size, 16, input_length= max_sequence_len),\n",
        " keras.layers.Bidirectional(keras.layers.LSTM(32)),\n",
        "keras.layers.Dense(24, activation='relu'),\n",
        "keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer = \"adam\",\n",
        "    metrics = [\"accuracy\"]\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyAq5Aws9NDb",
        "colab_type": "text"
      },
      "source": [
        "#**Training our model**\n",
        "\n",
        "- if it start training, \n",
        "\n",
        "- so do you have any plan for next 30 minutes just go for it and came back later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXDoc8x5if7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "c949cf0d-b677-4d44-9f0d-b5c9ab7ae5c7"
      },
      "source": [
        "model.fit(training_padded, training_labels, epochs = 12, batch_size = 128, validation_data= (testing_padded, testing_labels))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "665/665 [==============================] - 378s 568ms/step - loss: 0.3622 - accuracy: 0.8414 - val_loss: 0.2965 - val_accuracy: 0.8805\n",
            "Epoch 2/12\n",
            "665/665 [==============================] - 376s 565ms/step - loss: 0.2563 - accuracy: 0.8970 - val_loss: 0.2868 - val_accuracy: 0.8818\n",
            "Epoch 3/12\n",
            "665/665 [==============================] - 373s 560ms/step - loss: 0.2194 - accuracy: 0.9140 - val_loss: 0.2968 - val_accuracy: 0.8842\n",
            "Epoch 4/12\n",
            "665/665 [==============================] - 373s 560ms/step - loss: 0.1900 - accuracy: 0.9271 - val_loss: 0.3473 - val_accuracy: 0.8771\n",
            "Epoch 5/12\n",
            "665/665 [==============================] - 375s 564ms/step - loss: 0.1643 - accuracy: 0.9381 - val_loss: 0.3324 - val_accuracy: 0.8765\n",
            "Epoch 6/12\n",
            "665/665 [==============================] - 379s 570ms/step - loss: 0.1416 - accuracy: 0.9475 - val_loss: 0.3731 - val_accuracy: 0.8649\n",
            "Epoch 7/12\n",
            "665/665 [==============================] - 376s 566ms/step - loss: 0.1231 - accuracy: 0.9553 - val_loss: 0.3547 - val_accuracy: 0.8764\n",
            "Epoch 8/12\n",
            "665/665 [==============================] - 377s 567ms/step - loss: 0.1079 - accuracy: 0.9618 - val_loss: 0.4003 - val_accuracy: 0.8736\n",
            "Epoch 9/12\n",
            "665/665 [==============================] - 377s 566ms/step - loss: 0.0979 - accuracy: 0.9659 - val_loss: 0.4581 - val_accuracy: 0.8743\n",
            "Epoch 10/12\n",
            "665/665 [==============================] - 376s 566ms/step - loss: 0.0882 - accuracy: 0.9694 - val_loss: 0.4691 - val_accuracy: 0.8642\n",
            "Epoch 11/12\n",
            "665/665 [==============================] - 377s 568ms/step - loss: 0.0762 - accuracy: 0.9743 - val_loss: 0.5050 - val_accuracy: 0.8658\n",
            "Epoch 12/12\n",
            "665/665 [==============================] - 377s 567ms/step - loss: 0.0755 - accuracy: 0.9745 - val_loss: 0.4908 - val_accuracy: 0.8650\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5871cdf748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N579nep295NP",
        "colab_type": "text"
      },
      "source": [
        "our model is overfitting the data but our validation accuracy increasing  yeah that's good sign\n",
        "\n",
        "if you have more time just increase the epochs values ( 15, 20, 50).....\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJHvFDmO-ji5",
        "colab_type": "text"
      },
      "source": [
        "#**Save the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u5rxQ_I3hgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"amazon_reviews.h5\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8F8vIzP-u2L",
        "colab_type": "text"
      },
      "source": [
        "#**Loading our model**\n",
        "\n",
        "well i try to give another notebook for loading our saved model\n",
        "\n",
        "because to reduce the training time \n",
        "\n",
        "(if you want to train it just go for it and try to increase the validation accuracy )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPu8Tk7e7PTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = \"/content/amazon_reviews.h5\""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqBlB-k9Z6Lu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZzK03NzaBJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model(model_path)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr9mnXYuaFXk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "4ec22d5e-e232-4b27-8836-70becfcb2657"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 2917, 16)          1179808   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 64)                12544     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 24)                1560      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 25        \n",
            "=================================================================\n",
            "Total params: 1,193,937\n",
            "Trainable params: 1,193,937\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJbIe2_c_0VB",
        "colab_type": "text"
      },
      "source": [
        "#**Predicting the reviews**\n",
        "\n",
        "for prediction , \n",
        "\n",
        "- first thing we need a tokenizer to convert the output text into vector(numbered)\n",
        "\n",
        "- we need to padding it and then going for prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEsMtKSTfIpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction(model, text):\n",
        "  sequences = tokenizer.texts_to_sequences([text])\n",
        "  padded = pad_sequences(sequences, maxlen = max_sequence_len, truncating = \"post\")\n",
        "  reviews = model.predict(padded)\n",
        "\n",
        "  if reviews[0]>0.5:\n",
        "    print(\"it is a positive percent : \",str(reviews[0][0]*100)[:3])\n",
        "  else:\n",
        "    print(\"it is a negative percent : \",str(reviews[0][0]*100)[:3])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "581uiRZjAop5",
        "colab_type": "text"
      },
      "source": [
        "now calling the function , with output text\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8e4NRS3mP84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2c5f31e3-5a93-4ed0-f45a-1ebcc92cd5ac"
      },
      "source": [
        "\n",
        "text = \"i don't know why i buy this\"\n",
        "prediction(model, text)\n",
        "print(text)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it is a negative percent :  11.\n",
            "i don't know why i buy this\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrrjrIgHA533",
        "colab_type": "text"
      },
      "source": [
        "wow, negative reviews and lets make it complicated output text\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CiuX_lZmfDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "74e91cab-bd1a-49be-df9e-f3568da15480"
      },
      "source": [
        "text = \" waste product very much disappointing\"\n",
        "prediction(model, text)\n",
        "print(text)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it is a negative percent :  0.0\n",
            " waste product very much disappointing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpZ9V6oQwLgO",
        "colab_type": "text"
      },
      "source": [
        "okay let see the positive reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOtKIdUuBO9D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e6d50c30-80cd-476d-e2e4-3f8a258aa4f2"
      },
      "source": [
        "text = \"recently i got my laptop and it perform super cool\"\n",
        "prediction(model, text)\n",
        "print(text)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it is a positive percent :  99.\n",
            "recently i got my laptop and it perform super cool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSRSvSLPziPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}