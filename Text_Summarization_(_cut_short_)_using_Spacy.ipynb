{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Summarization ( cut short ) using Spacy ",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMr1mm9ksaOuF7tGUrNxuf/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jawaluke/DL-NLP-natural-language-processing-/blob/master/Text_Summarization_(_cut_short_)_using_Spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttfZwMjn1uMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dependencies\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "import string\n",
        "from string import punctuation"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl1o4Eje3JU-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35ee47d8-db12-429e-bcd0-730ec89b78c3"
      },
      "source": [
        "# total no of stop words\n",
        "\n",
        "stopword = list(STOP_WORDS)\n",
        "len(stopword)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsaMcCsh382F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"\"\"Gensim = “Generate Similar” is a popular open source natural language processing (NLP) library used for unsupervised topic modeling. It uses top academic models and modern statistical machine learning to perform various complex tasks such as −\n",
        "\n",
        "Building document or word vectors\n",
        "Corpora\n",
        "Performing topic identification\n",
        "Performing document comparison (retrieving semantically similar documents)\n",
        "Analysing plain-text documents for semantic structure\n",
        "Apart from performing the above complex tasks, Gensim, implemented in Python and Cython, is designed to handle large text collections using data streaming as well as incremental online algorithms. This makes it different from those machine learning software packages that target only in-memory processing.\n",
        "\n",
        "History\n",
        "In 2008, Gensim started off as a collection of various Python scripts for the Czech Digital Mathematics. There, it served to generate a short list of the most similar articles to a particular given article. But in 2009, RARE Technologies Ltd. released its initial release. Then, later in July 2019, we got its stable release (3.8.0).\n",
        "\n",
        "Various Features\n",
        "Following are some of the features and capabilities offered by Gensim −\n",
        "\n",
        "Scalability\n",
        "Gensim can easily process large and web-scale corpora by using its incremental online training algorithms. It is scalable in nature, as there is no need for the whole input corpus to reside fully in Random Access Memory (RAM) at any one time. In other words, all its algorithms are memory-independent with respect to the corpus size.\n",
        "\n",
        "Robust\n",
        "Gensim is robust in nature and has been in use in various systems by various people as well as organisations for over 4 years. We can easily plug in our own input corpus or data stream. It is also very easy to extend with other Vector Space Algorithms.\n",
        "\n",
        "Platform Agnostic\n",
        "As we know that Python is a very versatile language as being pure Python Gensim runs on all the platforms (like Windows, Mac OS, Linux) that supports Python and Numpy.\n",
        "\n",
        "Efficient Multicore Implementations\n",
        "In order to speed up processing and retrieval on machine clusters, Gensim provides efficient multicore implementations of various popular algorithms like Latent Semantic Analysis (LSA), Latent Dirichlet Allocation (LDA), Random Projections (RP), Hierarchical Dirichlet Process (HDP).\n",
        "\n",
        "Open Source and Abundance of Community Support\n",
        "Gensim is licensed under the OSI-approved GNU LGPL license which allows it to be used for both personal as well as commercial use for free. Any modifications made in Gensim are in turn open-sourced and has abundance of community support too.\n",
        "\n",
        "Uses of Gensim\n",
        "Gensim has been used and cited in over thousand commercial and academic applications. It is also cited by various research papers and student theses. It includes streamed parallelised implementations of the following −\n",
        "\n",
        "fastText\n",
        "fastText, uses a neural network for word embedding, is a library for learning of word embedding and text classification. It is created by Facebook’s AI Research (FAIR) lab. This model, basically, allows us to create a supervised or unsupervised algorithm for obtaining vector representations for words.\n",
        "\n",
        "Word2vec\n",
        "Word2vec, used to produce word embedding, is a group of shallow and two-layer neural network models. The models are basically trained to reconstruct linguistic contexts of words.\n",
        "\n",
        "LSA (Latent Semantic Analysis)\n",
        "It is a technique in NLP (Natural Language Processing) that allows us to analyse relationships between a set of documents and their containing terms. It is done by producing a set of concepts related to the documents and terms.\n",
        "\n",
        "LDA (Latent Dirichlet Allocation)\n",
        "It is a technique in NLP that allows sets of observations to be explained by unobserved groups. These unobserved groups explain, why some parts of the data are similar. That’s the reason, it is a generative statistical model.\n",
        "\n",
        "tf-idf (term frequency-inverse document frequency)\n",
        "tf-idf, a numeric statistic in information retrieval, reflects how important a word is to a document in a corpus. It is often used by search engines to score and rank a document’s relevance given a user query. It can also be used for stop-words filtering in text summarisation and classification.\n",
        "\n",
        "All of them will be explained in detail in the next sections.\n",
        "\n",
        "Advantages\n",
        "Gensim is a NLP package that does topic modeling. The important advantages of Gensim are as follows −\n",
        "\n",
        "We may get the facilities of topic modeling and word embedding in other packages like ‘scikit-learn’ and ‘R’, but the facilities provided by Gensim for building topic models and word embedding is unparalleled. It also provides more convenient facilities for text processing.\n",
        "\n",
        "Another most significant advantage of Gensim is that, it let us handle large text files even without loading the whole file in memory.\n",
        "\n",
        "Gensim doesn’t require costly annotations or hand tagging of documents because it uses unsupervised models.\n",
        "\"\"\""
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTk5pPlM4hz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## first step\n",
        "\n",
        "doc = nlp(text)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOK4fjF64oIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = [i.text for i in doc]"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3cEHyW54pO-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ddfe34b9-73e5-4259-853c-0f45bddc6544"
      },
      "source": [
        "print(tokens)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Gensim', '=', '“', 'Generate', 'Similar', '”', 'is', 'a', 'popular', 'open', 'source', 'natural', 'language', 'processing', '(', 'NLP', ')', 'library', 'used', 'for', 'unsupervised', 'topic', 'modeling', '.', 'It', 'uses', 'top', 'academic', 'models', 'and', 'modern', 'statistical', 'machine', 'learning', 'to', 'perform', 'various', 'complex', 'tasks', 'such', 'as', '−', '\\n\\n', 'Building', 'document', 'or', 'word', 'vectors', '\\n', 'Corpora', '\\n', 'Performing', 'topic', 'identification', '\\n', 'Performing', 'document', 'comparison', '(', 'retrieving', 'semantically', 'similar', 'documents', ')', '\\n', 'Analysing', 'plain', '-', 'text', 'documents', 'for', 'semantic', 'structure', '\\n', 'Apart', 'from', 'performing', 'the', 'above', 'complex', 'tasks', ',', 'Gensim', ',', 'implemented', 'in', 'Python', 'and', 'Cython', ',', 'is', 'designed', 'to', 'handle', 'large', 'text', 'collections', 'using', 'data', 'streaming', 'as', 'well', 'as', 'incremental', 'online', 'algorithms', '.', 'This', 'makes', 'it', 'different', 'from', 'those', 'machine', 'learning', 'software', 'packages', 'that', 'target', 'only', 'in', '-', 'memory', 'processing', '.', '\\n\\n', 'History', '\\n', 'In', '2008', ',', 'Gensim', 'started', 'off', 'as', 'a', 'collection', 'of', 'various', 'Python', 'scripts', 'for', 'the', 'Czech', 'Digital', 'Mathematics', '.', 'There', ',', 'it', 'served', 'to', 'generate', 'a', 'short', 'list', 'of', 'the', 'most', 'similar', 'articles', 'to', 'a', 'particular', 'given', 'article', '.', 'But', 'in', '2009', ',', 'RARE', 'Technologies', 'Ltd.', 'released', 'its', 'initial', 'release', '.', 'Then', ',', 'later', 'in', 'July', '2019', ',', 'we', 'got', 'its', 'stable', 'release', '(', '3.8.0', ')', '.', '\\n\\n', 'Various', 'Features', '\\n', 'Following', 'are', 'some', 'of', 'the', 'features', 'and', 'capabilities', 'offered', 'by', 'Gensim', '−', '\\n\\n', 'Scalability', '\\n', 'Gensim', 'can', 'easily', 'process', 'large', 'and', 'web', '-', 'scale', 'corpora', 'by', 'using', 'its', 'incremental', 'online', 'training', 'algorithms', '.', 'It', 'is', 'scalable', 'in', 'nature', ',', 'as', 'there', 'is', 'no', 'need', 'for', 'the', 'whole', 'input', 'corpus', 'to', 'reside', 'fully', 'in', 'Random', 'Access', 'Memory', '(', 'RAM', ')', 'at', 'any', 'one', 'time', '.', 'In', 'other', 'words', ',', 'all', 'its', 'algorithms', 'are', 'memory', '-', 'independent', 'with', 'respect', 'to', 'the', 'corpus', 'size', '.', '\\n\\n', 'Robust', '\\n', 'Gensim', 'is', 'robust', 'in', 'nature', 'and', 'has', 'been', 'in', 'use', 'in', 'various', 'systems', 'by', 'various', 'people', 'as', 'well', 'as', 'organisations', 'for', 'over', '4', 'years', '.', 'We', 'can', 'easily', 'plug', 'in', 'our', 'own', 'input', 'corpus', 'or', 'data', 'stream', '.', 'It', 'is', 'also', 'very', 'easy', 'to', 'extend', 'with', 'other', 'Vector', 'Space', 'Algorithms', '.', '\\n\\n', 'Platform', 'Agnostic', '\\n', 'As', 'we', 'know', 'that', 'Python', 'is', 'a', 'very', 'versatile', 'language', 'as', 'being', 'pure', 'Python', 'Gensim', 'runs', 'on', 'all', 'the', 'platforms', '(', 'like', 'Windows', ',', 'Mac', 'OS', ',', 'Linux', ')', 'that', 'supports', 'Python', 'and', 'Numpy', '.', '\\n\\n', 'Efficient', 'Multicore', 'Implementations', '\\n', 'In', 'order', 'to', 'speed', 'up', 'processing', 'and', 'retrieval', 'on', 'machine', 'clusters', ',', 'Gensim', 'provides', 'efficient', 'multicore', 'implementations', 'of', 'various', 'popular', 'algorithms', 'like', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', ',', 'Latent', 'Dirichlet', 'Allocation', '(', 'LDA', ')', ',', 'Random', 'Projections', '(', 'RP', ')', ',', 'Hierarchical', 'Dirichlet', 'Process', '(', 'HDP', ')', '.', '\\n\\n', 'Open', 'Source', 'and', 'Abundance', 'of', 'Community', 'Support', '\\n', 'Gensim', 'is', 'licensed', 'under', 'the', 'OSI', '-', 'approved', 'GNU', 'LGPL', 'license', 'which', 'allows', 'it', 'to', 'be', 'used', 'for', 'both', 'personal', 'as', 'well', 'as', 'commercial', 'use', 'for', 'free', '.', 'Any', 'modifications', 'made', 'in', 'Gensim', 'are', 'in', 'turn', 'open', '-', 'sourced', 'and', 'has', 'abundance', 'of', 'community', 'support', 'too', '.', '\\n\\n', 'Uses', 'of', 'Gensim', '\\n', 'Gensim', 'has', 'been', 'used', 'and', 'cited', 'in', 'over', 'thousand', 'commercial', 'and', 'academic', 'applications', '.', 'It', 'is', 'also', 'cited', 'by', 'various', 'research', 'papers', 'and', 'student', 'theses', '.', 'It', 'includes', 'streamed', 'parallelised', 'implementations', 'of', 'the', 'following', '−', '\\n\\n', 'fastText', '\\n', 'fastText', ',', 'uses', 'a', 'neural', 'network', 'for', 'word', 'embedding', ',', 'is', 'a', 'library', 'for', 'learning', 'of', 'word', 'embedding', 'and', 'text', 'classification', '.', 'It', 'is', 'created', 'by', 'Facebook', '’s', 'AI', 'Research', '(', 'FAIR', ')', 'lab', '.', 'This', 'model', ',', 'basically', ',', 'allows', 'us', 'to', 'create', 'a', 'supervised', 'or', 'unsupervised', 'algorithm', 'for', 'obtaining', 'vector', 'representations', 'for', 'words', '.', '\\n\\n', 'Word2vec', '\\n', 'Word2vec', ',', 'used', 'to', 'produce', 'word', 'embedding', ',', 'is', 'a', 'group', 'of', 'shallow', 'and', 'two', '-', 'layer', 'neural', 'network', 'models', '.', 'The', 'models', 'are', 'basically', 'trained', 'to', 'reconstruct', 'linguistic', 'contexts', 'of', 'words', '.', '\\n\\n', 'LSA', '(', 'Latent', 'Semantic', 'Analysis', ')', '\\n', 'It', 'is', 'a', 'technique', 'in', 'NLP', '(', 'Natural', 'Language', 'Processing', ')', 'that', 'allows', 'us', 'to', 'analyse', 'relationships', 'between', 'a', 'set', 'of', 'documents', 'and', 'their', 'containing', 'terms', '.', 'It', 'is', 'done', 'by', 'producing', 'a', 'set', 'of', 'concepts', 'related', 'to', 'the', 'documents', 'and', 'terms', '.', '\\n\\n', 'LDA', '(', 'Latent', 'Dirichlet', 'Allocation', ')', '\\n', 'It', 'is', 'a', 'technique', 'in', 'NLP', 'that', 'allows', 'sets', 'of', 'observations', 'to', 'be', 'explained', 'by', 'unobserved', 'groups', '.', 'These', 'unobserved', 'groups', 'explain', ',', 'why', 'some', 'parts', 'of', 'the', 'data', 'are', 'similar', '.', 'That', '’s', 'the', 'reason', ',', 'it', 'is', 'a', 'generative', 'statistical', 'model', '.', '\\n\\n', 'tf', '-', 'idf', '(', 'term', 'frequency', '-', 'inverse', 'document', 'frequency', ')', '\\n', 'tf', '-', 'idf', ',', 'a', 'numeric', 'statistic', 'in', 'information', 'retrieval', ',', 'reflects', 'how', 'important', 'a', 'word', 'is', 'to', 'a', 'document', 'in', 'a', 'corpus', '.', 'It', 'is', 'often', 'used', 'by', 'search', 'engines', 'to', 'score', 'and', 'rank', 'a', 'document', '’s', 'relevance', 'given', 'a', 'user', 'query', '.', 'It', 'can', 'also', 'be', 'used', 'for', 'stop', '-', 'words', 'filtering', 'in', 'text', 'summarisation', 'and', 'classification', '.', '\\n\\n', 'All', 'of', 'them', 'will', 'be', 'explained', 'in', 'detail', 'in', 'the', 'next', 'sections', '.', '\\n\\n', 'Advantages', '\\n', 'Gensim', 'is', 'a', 'NLP', 'package', 'that', 'does', 'topic', 'modeling', '.', 'The', 'important', 'advantages', 'of', 'Gensim', 'are', 'as', 'follows', '−', '\\n\\n', 'We', 'may', 'get', 'the', 'facilities', 'of', 'topic', 'modeling', 'and', 'word', 'embedding', 'in', 'other', 'packages', 'like', '‘', 'scikit', '-', 'learn', '’', 'and', '‘', 'R', '’', ',', 'but', 'the', 'facilities', 'provided', 'by', 'Gensim', 'for', 'building', 'topic', 'models', 'and', 'word', 'embedding', 'is', 'unparalleled', '.', 'It', 'also', 'provides', 'more', 'convenient', 'facilities', 'for', 'text', 'processing', '.', '\\n\\n', 'Another', 'most', 'significant', 'advantage', 'of', 'Gensim', 'is', 'that', ',', 'it', 'let', 'us', 'handle', 'large', 'text', 'files', 'even', 'without', 'loading', 'the', 'whole', 'file', 'in', 'memory', '.', '\\n\\n', 'Gensim', 'does', 'n’t', 'require', 'costly', 'annotations', 'or', 'hand', 'tagging', 'of', 'documents', 'because', 'it', 'uses', 'unsupervised', 'models', '.', '\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcAYk15c4yRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0d7a4773-682c-4608-a3f9-363c5afd9fa7"
      },
      "source": [
        "# removal of puntuation\n",
        "\n",
        "punctuation = punctuation+\"\\n\\n \"+\"−\" # including the space also\n",
        "print(list(punctuation))"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '\\n', '\\n', '\\n', '\\n', '\\n', ' ', '\\n', '\\n', ' ', '\\n', '\\n', ' ', '\\n', '\\n', ' ', '\\n', '\\n', ' ', '\\n', '\\n', ' ', '\\n', '\\n', ' ', '\\n', '\\n', ' ', '\\n', '\\n', ' ', '\\n', '\\n', ' ', '−', '\\n', '\\n', ' ', '−']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPdRVhh65FES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def punctuation_removal(sentence):\n",
        "  sentence = sentence.split()\n",
        "  # punctuation\n",
        "  word_init = []\n",
        "  for word in sentence:\n",
        "    if not word in list(punctuation):\n",
        "      word_init.append(word.lower())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # removing of stopwords :\n",
        "  word_stop = []\n",
        "  for word in word_init:\n",
        "    if word not in stopword:\n",
        "      word_stop.append(word)\n",
        "\n",
        "\n",
        "  return word_stop\n",
        "  \n",
        "clean_list = punctuation_removal(text)\n",
        "\n",
        "# count of each words:\n",
        "def count_words(clean_list):\n",
        "  word_freq = {}\n",
        "  for words in clean_list:\n",
        "    if words not in word_freq.keys():\n",
        "      word_freq[words] = 1\n",
        "    else:\n",
        "      word_freq[words]+=1\n",
        "      \n",
        "\n",
        "  return word_freq\n",
        "\n",
        "\n",
        "\n",
        "word_counts = count_words(clean_list)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMf5Z5P059Yi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "abd9add2-c809-4b38-87b1-b3994934b029"
      },
      "source": [
        "print(clean_list)\n",
        "print(word_counts)\n",
        "print(\" the length of word_counts : \",len(word_counts))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['gensim', '“generate', 'similar”', 'popular', 'open', 'source', 'natural', 'language', 'processing', '(nlp)', 'library', 'unsupervised', 'topic', 'modeling.', 'uses', 'academic', 'models', 'modern', 'statistical', 'machine', 'learning', 'perform', 'complex', 'tasks', 'building', 'document', 'word', 'vectors', 'corpora', 'performing', 'topic', 'identification', 'performing', 'document', 'comparison', '(retrieving', 'semantically', 'similar', 'documents)', 'analysing', 'plain-text', 'documents', 'semantic', 'structure', 'apart', 'performing', 'complex', 'tasks,', 'gensim,', 'implemented', 'python', 'cython,', 'designed', 'handle', 'large', 'text', 'collections', 'data', 'streaming', 'incremental', 'online', 'algorithms.', 'makes', 'different', 'machine', 'learning', 'software', 'packages', 'target', 'in-memory', 'processing.', 'history', '2008,', 'gensim', 'started', 'collection', 'python', 'scripts', 'czech', 'digital', 'mathematics.', 'there,', 'served', 'generate', 'short', 'list', 'similar', 'articles', 'particular', 'given', 'article.', '2009,', 'rare', 'technologies', 'ltd.', 'released', 'initial', 'release.', 'then,', 'later', 'july', '2019,', 'got', 'stable', 'release', '(3.8.0).', 'features', 'following', 'features', 'capabilities', 'offered', 'gensim', 'scalability', 'gensim', 'easily', 'process', 'large', 'web-scale', 'corpora', 'incremental', 'online', 'training', 'algorithms.', 'scalable', 'nature,', 'need', 'input', 'corpus', 'reside', 'fully', 'random', 'access', 'memory', '(ram)', 'time.', 'words,', 'algorithms', 'memory-independent', 'respect', 'corpus', 'size.', 'robust', 'gensim', 'robust', 'nature', 'use', 'systems', 'people', 'organisations', '4', 'years.', 'easily', 'plug', 'input', 'corpus', 'data', 'stream.', 'easy', 'extend', 'vector', 'space', 'algorithms.', 'platform', 'agnostic', 'know', 'python', 'versatile', 'language', 'pure', 'python', 'gensim', 'runs', 'platforms', '(like', 'windows,', 'mac', 'os,', 'linux)', 'supports', 'python', 'numpy.', 'efficient', 'multicore', 'implementations', 'order', 'speed', 'processing', 'retrieval', 'machine', 'clusters,', 'gensim', 'provides', 'efficient', 'multicore', 'implementations', 'popular', 'algorithms', 'like', 'latent', 'semantic', 'analysis', '(lsa),', 'latent', 'dirichlet', 'allocation', '(lda),', 'random', 'projections', '(rp),', 'hierarchical', 'dirichlet', 'process', '(hdp).', 'open', 'source', 'abundance', 'community', 'support', 'gensim', 'licensed', 'osi-approved', 'gnu', 'lgpl', 'license', 'allows', 'personal', 'commercial', 'use', 'free.', 'modifications', 'gensim', 'turn', 'open-sourced', 'abundance', 'community', 'support', 'too.', 'uses', 'gensim', 'gensim', 'cited', 'thousand', 'commercial', 'academic', 'applications.', 'cited', 'research', 'papers', 'student', 'theses.', 'includes', 'streamed', 'parallelised', 'implementations', 'following', 'fasttext', 'fasttext,', 'uses', 'neural', 'network', 'word', 'embedding,', 'library', 'learning', 'word', 'embedding', 'text', 'classification.', 'created', 'facebook’s', 'ai', 'research', '(fair)', 'lab.', 'model,', 'basically,', 'allows', 'create', 'supervised', 'unsupervised', 'algorithm', 'obtaining', 'vector', 'representations', 'words.', 'word2vec', 'word2vec,', 'produce', 'word', 'embedding,', 'group', 'shallow', 'two-layer', 'neural', 'network', 'models.', 'models', 'basically', 'trained', 'reconstruct', 'linguistic', 'contexts', 'words.', 'lsa', '(latent', 'semantic', 'analysis)', 'technique', 'nlp', '(natural', 'language', 'processing)', 'allows', 'analyse', 'relationships', 'set', 'documents', 'containing', 'terms.', 'producing', 'set', 'concepts', 'related', 'documents', 'terms.', 'lda', '(latent', 'dirichlet', 'allocation)', 'technique', 'nlp', 'allows', 'sets', 'observations', 'explained', 'unobserved', 'groups.', 'unobserved', 'groups', 'explain,', 'parts', 'data', 'similar.', 'that’s', 'reason,', 'generative', 'statistical', 'model.', 'tf-idf', '(term', 'frequency-inverse', 'document', 'frequency)', 'tf-idf,', 'numeric', 'statistic', 'information', 'retrieval,', 'reflects', 'important', 'word', 'document', 'corpus.', 'search', 'engines', 'score', 'rank', 'document’s', 'relevance', 'given', 'user', 'query.', 'stop-words', 'filtering', 'text', 'summarisation', 'classification.', 'explained', 'detail', 'sections.', 'advantages', 'gensim', 'nlp', 'package', 'topic', 'modeling.', 'important', 'advantages', 'gensim', 'follows', 'facilities', 'topic', 'modeling', 'word', 'embedding', 'packages', 'like', '‘scikit-learn’', '‘r’,', 'facilities', 'provided', 'gensim', 'building', 'topic', 'models', 'word', 'embedding', 'unparalleled.', 'provides', 'convenient', 'facilities', 'text', 'processing.', 'significant', 'advantage', 'gensim', 'that,', 'let', 'handle', 'large', 'text', 'files', 'loading', 'file', 'memory.', 'gensim', 'doesn’t', 'require', 'costly', 'annotations', 'hand', 'tagging', 'documents', 'uses', 'unsupervised', 'models.']\n",
            "{'gensim': 16, '“generate': 1, 'similar”': 1, 'popular': 2, 'open': 2, 'source': 2, 'natural': 1, 'language': 3, 'processing': 2, '(nlp)': 1, 'library': 2, 'unsupervised': 3, 'topic': 5, 'modeling.': 2, 'uses': 4, 'academic': 2, 'models': 3, 'modern': 1, 'statistical': 2, 'machine': 3, 'learning': 3, 'perform': 1, 'complex': 2, 'tasks': 1, 'building': 2, 'document': 4, 'word': 7, 'vectors': 1, 'corpora': 2, 'performing': 3, 'identification': 1, 'comparison': 1, '(retrieving': 1, 'semantically': 1, 'similar': 2, 'documents)': 1, 'analysing': 1, 'plain-text': 1, 'documents': 4, 'semantic': 3, 'structure': 1, 'apart': 1, 'tasks,': 1, 'gensim,': 1, 'implemented': 1, 'python': 5, 'cython,': 1, 'designed': 1, 'handle': 2, 'large': 3, 'text': 5, 'collections': 1, 'data': 3, 'streaming': 1, 'incremental': 2, 'online': 2, 'algorithms.': 3, 'makes': 1, 'different': 1, 'software': 1, 'packages': 2, 'target': 1, 'in-memory': 1, 'processing.': 2, 'history': 1, '2008,': 1, 'started': 1, 'collection': 1, 'scripts': 1, 'czech': 1, 'digital': 1, 'mathematics.': 1, 'there,': 1, 'served': 1, 'generate': 1, 'short': 1, 'list': 1, 'articles': 1, 'particular': 1, 'given': 2, 'article.': 1, '2009,': 1, 'rare': 1, 'technologies': 1, 'ltd.': 1, 'released': 1, 'initial': 1, 'release.': 1, 'then,': 1, 'later': 1, 'july': 1, '2019,': 1, 'got': 1, 'stable': 1, 'release': 1, '(3.8.0).': 1, 'features': 2, 'following': 2, 'capabilities': 1, 'offered': 1, 'scalability': 1, 'easily': 2, 'process': 2, 'web-scale': 1, 'training': 1, 'scalable': 1, 'nature,': 1, 'need': 1, 'input': 2, 'corpus': 3, 'reside': 1, 'fully': 1, 'random': 2, 'access': 1, 'memory': 1, '(ram)': 1, 'time.': 1, 'words,': 1, 'algorithms': 2, 'memory-independent': 1, 'respect': 1, 'size.': 1, 'robust': 2, 'nature': 1, 'use': 2, 'systems': 1, 'people': 1, 'organisations': 1, '4': 1, 'years.': 1, 'plug': 1, 'stream.': 1, 'easy': 1, 'extend': 1, 'vector': 2, 'space': 1, 'platform': 1, 'agnostic': 1, 'know': 1, 'versatile': 1, 'pure': 1, 'runs': 1, 'platforms': 1, '(like': 1, 'windows,': 1, 'mac': 1, 'os,': 1, 'linux)': 1, 'supports': 1, 'numpy.': 1, 'efficient': 2, 'multicore': 2, 'implementations': 3, 'order': 1, 'speed': 1, 'retrieval': 1, 'clusters,': 1, 'provides': 2, 'like': 2, 'latent': 2, 'analysis': 1, '(lsa),': 1, 'dirichlet': 3, 'allocation': 1, '(lda),': 1, 'projections': 1, '(rp),': 1, 'hierarchical': 1, '(hdp).': 1, 'abundance': 2, 'community': 2, 'support': 2, 'licensed': 1, 'osi-approved': 1, 'gnu': 1, 'lgpl': 1, 'license': 1, 'allows': 4, 'personal': 1, 'commercial': 2, 'free.': 1, 'modifications': 1, 'turn': 1, 'open-sourced': 1, 'too.': 1, 'cited': 2, 'thousand': 1, 'applications.': 1, 'research': 2, 'papers': 1, 'student': 1, 'theses.': 1, 'includes': 1, 'streamed': 1, 'parallelised': 1, 'fasttext': 1, 'fasttext,': 1, 'neural': 2, 'network': 2, 'embedding,': 2, 'embedding': 3, 'classification.': 2, 'created': 1, 'facebook’s': 1, 'ai': 1, '(fair)': 1, 'lab.': 1, 'model,': 1, 'basically,': 1, 'create': 1, 'supervised': 1, 'algorithm': 1, 'obtaining': 1, 'representations': 1, 'words.': 2, 'word2vec': 1, 'word2vec,': 1, 'produce': 1, 'group': 1, 'shallow': 1, 'two-layer': 1, 'models.': 2, 'basically': 1, 'trained': 1, 'reconstruct': 1, 'linguistic': 1, 'contexts': 1, 'lsa': 1, '(latent': 2, 'analysis)': 1, 'technique': 2, 'nlp': 3, '(natural': 1, 'processing)': 1, 'analyse': 1, 'relationships': 1, 'set': 2, 'containing': 1, 'terms.': 2, 'producing': 1, 'concepts': 1, 'related': 1, 'lda': 1, 'allocation)': 1, 'sets': 1, 'observations': 1, 'explained': 2, 'unobserved': 2, 'groups.': 1, 'groups': 1, 'explain,': 1, 'parts': 1, 'similar.': 1, 'that’s': 1, 'reason,': 1, 'generative': 1, 'model.': 1, 'tf-idf': 1, '(term': 1, 'frequency-inverse': 1, 'frequency)': 1, 'tf-idf,': 1, 'numeric': 1, 'statistic': 1, 'information': 1, 'retrieval,': 1, 'reflects': 1, 'important': 2, 'corpus.': 1, 'search': 1, 'engines': 1, 'score': 1, 'rank': 1, 'document’s': 1, 'relevance': 1, 'user': 1, 'query.': 1, 'stop-words': 1, 'filtering': 1, 'summarisation': 1, 'detail': 1, 'sections.': 1, 'advantages': 2, 'package': 1, 'follows': 1, 'facilities': 3, 'modeling': 1, '‘scikit-learn’': 1, '‘r’,': 1, 'provided': 1, 'unparalleled.': 1, 'convenient': 1, 'significant': 1, 'advantage': 1, 'that,': 1, 'let': 1, 'files': 1, 'loading': 1, 'file': 1, 'memory.': 1, 'doesn’t': 1, 'require': 1, 'costly': 1, 'annotations': 1, 'hand': 1, 'tagging': 1}\n",
            " the length of word_counts :  306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMAKDZZZCtpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting the max of word counts\n",
        "\n",
        "max_counts = max(word_counts.values())"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PvY3AMJE16V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3a711cb-9294-45db-b5a9-0174abcda0c1"
      },
      "source": [
        "max_counts"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDX3lp_AFdSL",
        "colab_type": "text"
      },
      "source": [
        "#**We divide each frequencies by max frequencies (word_count dict / max_counts)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoKxNUJJE31a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_frequencies = {}\n",
        "\n",
        "for words in word_counts.keys():\n",
        "  word_frequencies[words] = word_counts[words]/max_counts"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4qe3mbOGZF0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fe5f4ca9-0b6e-47a0-8b06-2857d7246369"
      },
      "source": [
        "word_frequencies"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'(3.8.0).': 0.0625,\n",
              " '(fair)': 0.0625,\n",
              " '(hdp).': 0.0625,\n",
              " '(latent': 0.125,\n",
              " '(lda),': 0.0625,\n",
              " '(like': 0.0625,\n",
              " '(lsa),': 0.0625,\n",
              " '(natural': 0.0625,\n",
              " '(nlp)': 0.0625,\n",
              " '(ram)': 0.0625,\n",
              " '(retrieving': 0.0625,\n",
              " '(rp),': 0.0625,\n",
              " '(term': 0.0625,\n",
              " '2008,': 0.0625,\n",
              " '2009,': 0.0625,\n",
              " '2019,': 0.0625,\n",
              " '4': 0.0625,\n",
              " 'abundance': 0.125,\n",
              " 'academic': 0.125,\n",
              " 'access': 0.0625,\n",
              " 'advantage': 0.0625,\n",
              " 'advantages': 0.125,\n",
              " 'agnostic': 0.0625,\n",
              " 'ai': 0.0625,\n",
              " 'algorithm': 0.0625,\n",
              " 'algorithms': 0.125,\n",
              " 'algorithms.': 0.1875,\n",
              " 'allocation': 0.0625,\n",
              " 'allocation)': 0.0625,\n",
              " 'allows': 0.25,\n",
              " 'analyse': 0.0625,\n",
              " 'analysing': 0.0625,\n",
              " 'analysis': 0.0625,\n",
              " 'analysis)': 0.0625,\n",
              " 'annotations': 0.0625,\n",
              " 'apart': 0.0625,\n",
              " 'applications.': 0.0625,\n",
              " 'article.': 0.0625,\n",
              " 'articles': 0.0625,\n",
              " 'basically': 0.0625,\n",
              " 'basically,': 0.0625,\n",
              " 'building': 0.125,\n",
              " 'capabilities': 0.0625,\n",
              " 'cited': 0.125,\n",
              " 'classification.': 0.125,\n",
              " 'clusters,': 0.0625,\n",
              " 'collection': 0.0625,\n",
              " 'collections': 0.0625,\n",
              " 'commercial': 0.125,\n",
              " 'community': 0.125,\n",
              " 'comparison': 0.0625,\n",
              " 'complex': 0.125,\n",
              " 'concepts': 0.0625,\n",
              " 'containing': 0.0625,\n",
              " 'contexts': 0.0625,\n",
              " 'convenient': 0.0625,\n",
              " 'corpora': 0.125,\n",
              " 'corpus': 0.1875,\n",
              " 'corpus.': 0.0625,\n",
              " 'costly': 0.0625,\n",
              " 'create': 0.0625,\n",
              " 'created': 0.0625,\n",
              " 'cython,': 0.0625,\n",
              " 'czech': 0.0625,\n",
              " 'data': 0.1875,\n",
              " 'designed': 0.0625,\n",
              " 'detail': 0.0625,\n",
              " 'different': 0.0625,\n",
              " 'digital': 0.0625,\n",
              " 'dirichlet': 0.1875,\n",
              " 'document': 0.25,\n",
              " 'documents': 0.25,\n",
              " 'documents)': 0.0625,\n",
              " 'document’s': 0.0625,\n",
              " 'doesn’t': 0.0625,\n",
              " 'easily': 0.125,\n",
              " 'easy': 0.0625,\n",
              " 'efficient': 0.125,\n",
              " 'embedding': 0.1875,\n",
              " 'embedding,': 0.125,\n",
              " 'engines': 0.0625,\n",
              " 'explain,': 0.0625,\n",
              " 'explained': 0.125,\n",
              " 'extend': 0.0625,\n",
              " 'facebook’s': 0.0625,\n",
              " 'facilities': 0.1875,\n",
              " 'fasttext': 0.0625,\n",
              " 'fasttext,': 0.0625,\n",
              " 'features': 0.125,\n",
              " 'file': 0.0625,\n",
              " 'files': 0.0625,\n",
              " 'filtering': 0.0625,\n",
              " 'following': 0.125,\n",
              " 'follows': 0.0625,\n",
              " 'free.': 0.0625,\n",
              " 'frequency)': 0.0625,\n",
              " 'frequency-inverse': 0.0625,\n",
              " 'fully': 0.0625,\n",
              " 'generate': 0.0625,\n",
              " 'generative': 0.0625,\n",
              " 'gensim': 1.0,\n",
              " 'gensim,': 0.0625,\n",
              " 'given': 0.125,\n",
              " 'gnu': 0.0625,\n",
              " 'got': 0.0625,\n",
              " 'group': 0.0625,\n",
              " 'groups': 0.0625,\n",
              " 'groups.': 0.0625,\n",
              " 'hand': 0.0625,\n",
              " 'handle': 0.125,\n",
              " 'hierarchical': 0.0625,\n",
              " 'history': 0.0625,\n",
              " 'identification': 0.0625,\n",
              " 'implementations': 0.1875,\n",
              " 'implemented': 0.0625,\n",
              " 'important': 0.125,\n",
              " 'in-memory': 0.0625,\n",
              " 'includes': 0.0625,\n",
              " 'incremental': 0.125,\n",
              " 'information': 0.0625,\n",
              " 'initial': 0.0625,\n",
              " 'input': 0.125,\n",
              " 'july': 0.0625,\n",
              " 'know': 0.0625,\n",
              " 'lab.': 0.0625,\n",
              " 'language': 0.1875,\n",
              " 'large': 0.1875,\n",
              " 'latent': 0.125,\n",
              " 'later': 0.0625,\n",
              " 'lda': 0.0625,\n",
              " 'learning': 0.1875,\n",
              " 'let': 0.0625,\n",
              " 'lgpl': 0.0625,\n",
              " 'library': 0.125,\n",
              " 'license': 0.0625,\n",
              " 'licensed': 0.0625,\n",
              " 'like': 0.125,\n",
              " 'linguistic': 0.0625,\n",
              " 'linux)': 0.0625,\n",
              " 'list': 0.0625,\n",
              " 'loading': 0.0625,\n",
              " 'lsa': 0.0625,\n",
              " 'ltd.': 0.0625,\n",
              " 'mac': 0.0625,\n",
              " 'machine': 0.1875,\n",
              " 'makes': 0.0625,\n",
              " 'mathematics.': 0.0625,\n",
              " 'memory': 0.0625,\n",
              " 'memory-independent': 0.0625,\n",
              " 'memory.': 0.0625,\n",
              " 'model,': 0.0625,\n",
              " 'model.': 0.0625,\n",
              " 'modeling': 0.0625,\n",
              " 'modeling.': 0.125,\n",
              " 'models': 0.1875,\n",
              " 'models.': 0.125,\n",
              " 'modern': 0.0625,\n",
              " 'modifications': 0.0625,\n",
              " 'multicore': 0.125,\n",
              " 'natural': 0.0625,\n",
              " 'nature': 0.0625,\n",
              " 'nature,': 0.0625,\n",
              " 'need': 0.0625,\n",
              " 'network': 0.125,\n",
              " 'neural': 0.125,\n",
              " 'nlp': 0.1875,\n",
              " 'numeric': 0.0625,\n",
              " 'numpy.': 0.0625,\n",
              " 'observations': 0.0625,\n",
              " 'obtaining': 0.0625,\n",
              " 'offered': 0.0625,\n",
              " 'online': 0.125,\n",
              " 'open': 0.125,\n",
              " 'open-sourced': 0.0625,\n",
              " 'order': 0.0625,\n",
              " 'organisations': 0.0625,\n",
              " 'os,': 0.0625,\n",
              " 'osi-approved': 0.0625,\n",
              " 'package': 0.0625,\n",
              " 'packages': 0.125,\n",
              " 'papers': 0.0625,\n",
              " 'parallelised': 0.0625,\n",
              " 'particular': 0.0625,\n",
              " 'parts': 0.0625,\n",
              " 'people': 0.0625,\n",
              " 'perform': 0.0625,\n",
              " 'performing': 0.1875,\n",
              " 'personal': 0.0625,\n",
              " 'plain-text': 0.0625,\n",
              " 'platform': 0.0625,\n",
              " 'platforms': 0.0625,\n",
              " 'plug': 0.0625,\n",
              " 'popular': 0.125,\n",
              " 'process': 0.125,\n",
              " 'processing': 0.125,\n",
              " 'processing)': 0.0625,\n",
              " 'processing.': 0.125,\n",
              " 'produce': 0.0625,\n",
              " 'producing': 0.0625,\n",
              " 'projections': 0.0625,\n",
              " 'provided': 0.0625,\n",
              " 'provides': 0.125,\n",
              " 'pure': 0.0625,\n",
              " 'python': 0.3125,\n",
              " 'query.': 0.0625,\n",
              " 'random': 0.125,\n",
              " 'rank': 0.0625,\n",
              " 'rare': 0.0625,\n",
              " 'reason,': 0.0625,\n",
              " 'reconstruct': 0.0625,\n",
              " 'reflects': 0.0625,\n",
              " 'related': 0.0625,\n",
              " 'relationships': 0.0625,\n",
              " 'release': 0.0625,\n",
              " 'release.': 0.0625,\n",
              " 'released': 0.0625,\n",
              " 'relevance': 0.0625,\n",
              " 'representations': 0.0625,\n",
              " 'require': 0.0625,\n",
              " 'research': 0.125,\n",
              " 'reside': 0.0625,\n",
              " 'respect': 0.0625,\n",
              " 'retrieval': 0.0625,\n",
              " 'retrieval,': 0.0625,\n",
              " 'robust': 0.125,\n",
              " 'runs': 0.0625,\n",
              " 'scalability': 0.0625,\n",
              " 'scalable': 0.0625,\n",
              " 'score': 0.0625,\n",
              " 'scripts': 0.0625,\n",
              " 'search': 0.0625,\n",
              " 'sections.': 0.0625,\n",
              " 'semantic': 0.1875,\n",
              " 'semantically': 0.0625,\n",
              " 'served': 0.0625,\n",
              " 'set': 0.125,\n",
              " 'sets': 0.0625,\n",
              " 'shallow': 0.0625,\n",
              " 'short': 0.0625,\n",
              " 'significant': 0.0625,\n",
              " 'similar': 0.125,\n",
              " 'similar.': 0.0625,\n",
              " 'similar”': 0.0625,\n",
              " 'size.': 0.0625,\n",
              " 'software': 0.0625,\n",
              " 'source': 0.125,\n",
              " 'space': 0.0625,\n",
              " 'speed': 0.0625,\n",
              " 'stable': 0.0625,\n",
              " 'started': 0.0625,\n",
              " 'statistic': 0.0625,\n",
              " 'statistical': 0.125,\n",
              " 'stop-words': 0.0625,\n",
              " 'stream.': 0.0625,\n",
              " 'streamed': 0.0625,\n",
              " 'streaming': 0.0625,\n",
              " 'structure': 0.0625,\n",
              " 'student': 0.0625,\n",
              " 'summarisation': 0.0625,\n",
              " 'supervised': 0.0625,\n",
              " 'support': 0.125,\n",
              " 'supports': 0.0625,\n",
              " 'systems': 0.0625,\n",
              " 'tagging': 0.0625,\n",
              " 'target': 0.0625,\n",
              " 'tasks': 0.0625,\n",
              " 'tasks,': 0.0625,\n",
              " 'technique': 0.125,\n",
              " 'technologies': 0.0625,\n",
              " 'terms.': 0.125,\n",
              " 'text': 0.3125,\n",
              " 'tf-idf': 0.0625,\n",
              " 'tf-idf,': 0.0625,\n",
              " 'that,': 0.0625,\n",
              " 'that’s': 0.0625,\n",
              " 'then,': 0.0625,\n",
              " 'there,': 0.0625,\n",
              " 'theses.': 0.0625,\n",
              " 'thousand': 0.0625,\n",
              " 'time.': 0.0625,\n",
              " 'too.': 0.0625,\n",
              " 'topic': 0.3125,\n",
              " 'trained': 0.0625,\n",
              " 'training': 0.0625,\n",
              " 'turn': 0.0625,\n",
              " 'two-layer': 0.0625,\n",
              " 'unobserved': 0.125,\n",
              " 'unparalleled.': 0.0625,\n",
              " 'unsupervised': 0.1875,\n",
              " 'use': 0.125,\n",
              " 'user': 0.0625,\n",
              " 'uses': 0.25,\n",
              " 'vector': 0.125,\n",
              " 'vectors': 0.0625,\n",
              " 'versatile': 0.0625,\n",
              " 'web-scale': 0.0625,\n",
              " 'windows,': 0.0625,\n",
              " 'word': 0.4375,\n",
              " 'word2vec': 0.0625,\n",
              " 'word2vec,': 0.0625,\n",
              " 'words,': 0.0625,\n",
              " 'words.': 0.125,\n",
              " 'years.': 0.0625,\n",
              " '‘r’,': 0.0625,\n",
              " '‘scikit-learn’': 0.0625,\n",
              " '“generate': 0.0625}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IueqlfrHeLs",
        "colab_type": "text"
      },
      "source": [
        "#**Now, lets tokenize the sentences**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hc3ZQ6RHnHc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a94e3ac-9583-4717-d146-9f3261cfe1af"
      },
      "source": [
        "# using spacy for tokenization\n",
        "\n",
        "sentence_tokens = [sent for sent in doc.sents]\n",
        "print(sentence_tokens)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Gensim =, “Generate Similar” is a popular open source natural language processing (NLP) library used for unsupervised topic modeling., It uses top academic models and modern statistical machine learning to perform various complex tasks such as −\n",
            "\n",
            ", Building document or word vectors\n",
            ", Corpora\n",
            "Performing topic identification\n",
            ", Performing document comparison (retrieving semantically similar documents)\n",
            ", Analysing plain-text documents for semantic structure\n",
            ", Apart from performing the above complex tasks, Gensim, implemented in Python and Cython, is designed to handle large text collections using data streaming as well as incremental online algorithms., This makes it different from those machine learning software packages that target only in-memory processing.\n",
            "\n",
            ", History\n",
            ", In 2008, Gensim started off as a collection of various Python scripts for the Czech Digital Mathematics., There, it served to generate a short list of the most similar articles to a particular given article., But in 2009, RARE Technologies Ltd. released its initial release., Then, later in July 2019, we got its stable release (3.8.0).\n",
            "\n",
            ", Various Features\n",
            ", Following are some of the features and capabilities offered by Gensim −\n",
            "\n",
            "Scalability\n",
            ", Gensim can easily process large and web-scale corpora by using its incremental online training algorithms., It is scalable in nature, as there is no need for the whole input corpus to reside fully in Random Access Memory (RAM) at any one time., In other words, all its algorithms are memory-independent with respect to the corpus size.\n",
            "\n",
            ", Robust\n",
            ", Gensim is robust in nature and has been in use in various systems by various people as well as organisations for over 4 years., We can easily plug in our own input corpus or data stream., It is also very easy to extend with other Vector Space Algorithms.\n",
            "\n",
            ", Platform Agnostic\n",
            ", As we know that Python is a very versatile language as being pure Python Gensim runs on all the platforms (like Windows, Mac OS, Linux) that supports Python and Numpy.\n",
            "\n",
            ", Efficient Multicore Implementations\n",
            ", In order to speed up processing and retrieval on machine clusters, Gensim provides efficient multicore implementations of various popular algorithms like Latent Semantic Analysis (LSA), Latent Dirichlet Allocation (LDA), Random Projections (RP), Hierarchical Dirichlet Process (HDP).\n",
            "\n",
            ", Open Source and Abundance of Community Support\n",
            ", Gensim is licensed under the OSI-approved GNU LGPL license which allows it to be used for both personal as well as commercial use for free., Any modifications made in Gensim are in turn open-sourced and has abundance of community support too.\n",
            "\n",
            ", Uses of Gensim\n",
            ", Gensim has been used and cited in over thousand commercial and academic applications., It is also cited by various research papers and student theses., It includes streamed parallelised implementations of the following −\n",
            "\n",
            ", fastText\n",
            "fastText, uses a neural network for word embedding, is a library for learning of word embedding and text classification., It is created by Facebook’s AI Research (FAIR) lab., This model, basically, allows us to create a supervised or unsupervised algorithm for obtaining vector representations for words.\n",
            "\n",
            ", Word2vec\n",
            "Word2vec, used to produce word embedding, is a group of shallow and two-layer neural network models., The models are basically trained to reconstruct linguistic contexts of words.\n",
            "\n",
            ", LSA (Latent Semantic Analysis)\n",
            ", It is a technique in NLP (Natural Language Processing) that allows us to analyse relationships between a set of documents and their containing terms., It is done by producing a set of concepts related to the documents and terms.\n",
            "\n",
            ", LDA (Latent Dirichlet Allocation)\n",
            ", It is a technique in NLP that allows sets of observations to be explained by unobserved groups., These unobserved groups explain, why some parts of the data are similar., That’s the reason, it is a generative statistical model.\n",
            "\n",
            ", tf-idf (term frequency-inverse document frequency)\n",
            ", tf-idf, a numeric statistic in information retrieval, reflects how important a word is to a document in a corpus., It is often used by search engines to score and rank a document, ’s relevance given a user query., It can also be used for stop-words filtering in text summarisation and classification.\n",
            "\n",
            ", All of them will be explained in detail in the next sections.\n",
            "\n",
            ", Advantages\n",
            ", Gensim is a NLP package that does topic modeling., The important advantages of Gensim are as follows −\n",
            "\n",
            ", We may get the facilities of topic modeling and word embedding in other packages like ‘scikit-learn’ and ‘R’, but the facilities provided by Gensim for building topic models and word embedding is unparalleled., It also provides more convenient facilities for text processing.\n",
            "\n",
            ", Another most significant advantage of Gensim is that, it let us handle large text files even without loading the whole file in memory.\n",
            "\n",
            ", Gensim doesn’t require costly annotations or hand tagging of documents because it uses unsupervised models.\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3HnfMz9Jvtn",
        "colab_type": "text"
      },
      "source": [
        "#**Sentence scores is like adding the word_frequencies to the sentences like**\n",
        "\n",
        "- eg : word_frequencies{ discovers : 0.2, efficiency : 1, relationships :0.2 }\n",
        "- sentence : its discovers the relationships between words\n",
        "- sentences frequency/ score : 0.2 + 0.2 = 0.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAYBBzJEIIl_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e90f47c2-a330-4050-8073-61b853abd732"
      },
      "source": [
        "# for sentences counts\n",
        "\n",
        "sentence_scores = {}\n",
        "\n",
        "for sent in sentence_tokens:\n",
        "  for word in sent:\n",
        "    if word.text.lower() in word_frequencies.keys():\n",
        "      if sent not in sentence_scores.keys():\n",
        "        sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
        "      else:\n",
        "        sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
        "\n",
        "sentence_scores"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{Gensim =: 1.0,\n",
              " “Generate Similar” is a popular open source natural language processing (NLP) library used for unsupervised topic modeling.: 1.8125,\n",
              " It uses top academic models and modern statistical machine learning to perform various complex tasks such as −\n",
              " : 1.375,\n",
              " Building document or word vectors: 0.875,\n",
              " Corpora\n",
              " Performing topic identification: 0.6875,\n",
              " Performing document comparison (retrieving semantically similar documents): 0.9375,\n",
              " Analysing plain-text documents for semantic structure: 0.875,\n",
              " Apart from performing the above complex tasks, Gensim, implemented in Python and Cython, is designed to handle large text collections using data streaming as well as incremental online algorithms.: 3.1875,\n",
              " This makes it different from those machine learning software packages that target only in-memory processing.\n",
              " : 0.9375,\n",
              " History: 0.0625,\n",
              " In 2008, Gensim started off as a collection of various Python scripts for the Czech Digital Mathematics.: 1.625,\n",
              " There, it served to generate a short list of the most similar articles to a particular given article.: 0.625,\n",
              " But in 2009, RARE Technologies Ltd. released its initial release.: 0.375,\n",
              " Then, later in July 2019, we got its stable release (3.8.0).\n",
              " : 0.3125,\n",
              " Various Features: 0.125,\n",
              " Following are some of the features and capabilities offered by Gensim −\n",
              " \n",
              " Scalability: 1.4375,\n",
              " Gensim can easily process large and web-scale corpora by using its incremental online training algorithms.: 2.0,\n",
              " It is scalable in nature, as there is no need for the whole input corpus to reside fully in Random Access Memory (RAM) at any one time.: 0.875,\n",
              " In other words, all its algorithms are memory-independent with respect to the corpus size.\n",
              " : 0.4375,\n",
              " Robust: 0.125,\n",
              " Gensim is robust in nature and has been in use in various systems by various people as well as organisations for over 4 years.: 1.5625,\n",
              " We can easily plug in our own input corpus or data stream.: 0.6875,\n",
              " It is also very easy to extend with other Vector Space Algorithms.\n",
              " : 0.4375,\n",
              " Platform Agnostic: 0.125,\n",
              " As we know that Python is a very versatile language as being pure Python Gensim runs on all the platforms (like Windows, Mac OS, Linux) that supports Python and Numpy.\n",
              " : 2.6875,\n",
              " Efficient Multicore Implementations: 0.4375,\n",
              " In order to speed up processing and retrieval on machine clusters, Gensim provides efficient multicore implementations of various popular algorithms like Latent Semantic Analysis (LSA), Latent Dirichlet Allocation (LDA), Random Projections (RP), Hierarchical Dirichlet Process (HDP).\n",
              " : 3.875,\n",
              " Open Source and Abundance of Community Support: 0.625,\n",
              " Gensim is licensed under the OSI-approved GNU LGPL license which allows it to be used for both personal as well as commercial use for free.: 1.8125,\n",
              " Any modifications made in Gensim are in turn open-sourced and has abundance of community support too.\n",
              " : 1.625,\n",
              " Uses of Gensim: 1.25,\n",
              " Gensim has been used and cited in over thousand commercial and academic applications.: 1.4375,\n",
              " It is also cited by various research papers and student theses.: 0.375,\n",
              " It includes streamed parallelised implementations of the following −\n",
              " : 0.5,\n",
              " fastText\n",
              " fastText, uses a neural network for word embedding, is a library for learning of word embedding and text classification.: 2.5,\n",
              " It is created by Facebook’s AI Research (FAIR) lab.: 0.25,\n",
              " This model, basically, allows us to create a supervised or unsupervised algorithm for obtaining vector representations for words.\n",
              " : 0.9375,\n",
              " Word2vec\n",
              " Word2vec, used to produce word embedding, is a group of shallow and two-layer neural network models.: 1.375,\n",
              " The models are basically trained to reconstruct linguistic contexts of words.\n",
              " : 0.5,\n",
              " LSA (Latent Semantic Analysis): 0.4375,\n",
              " It is a technique in NLP (Natural Language Processing) that allows us to analyse relationships between a set of documents and their containing terms.: 1.5,\n",
              " It is done by producing a set of concepts related to the documents and terms.\n",
              " : 0.5625,\n",
              " LDA (Latent Dirichlet Allocation): 0.4375,\n",
              " It is a technique in NLP that allows sets of observations to be explained by unobserved groups.: 1.0,\n",
              " These unobserved groups explain, why some parts of the data are similar.: 0.5625,\n",
              " That’s the reason, it is a generative statistical model.\n",
              " : 0.1875,\n",
              " tf-idf (term frequency-inverse document frequency): 0.25,\n",
              " tf-idf, a numeric statistic in information retrieval, reflects how important a word is to a document in a corpus.: 1.3125,\n",
              " It is often used by search engines to score and rank a document: 0.5,\n",
              " ’s relevance given a user query.: 0.25,\n",
              " It can also be used for stop-words filtering in text summarisation and classification.\n",
              " : 0.4375,\n",
              " All of them will be explained in detail in the next sections.\n",
              " : 0.1875,\n",
              " Advantages: 0.125,\n",
              " Gensim is a NLP package that does topic modeling.: 1.625,\n",
              " The important advantages of Gensim are as follows −\n",
              " : 1.3125,\n",
              " We may get the facilities of topic modeling and word embedding in other packages like ‘scikit-learn’ and ‘R’, but the facilities provided by Gensim for building topic models and word embedding is unparalleled.: 3.9375,\n",
              " It also provides more convenient facilities for text processing.\n",
              " : 0.8125,\n",
              " Another most significant advantage of Gensim is that, it let us handle large text files even without loading the whole file in memory.\n",
              " : 2.0625,\n",
              " Gensim doesn’t require costly annotations or hand tagging of documents because it uses unsupervised models.: 2.1875}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do4nRFfTLNV8",
        "colab_type": "text"
      },
      "source": [
        "#**Going to select 30% of the sentences having largest scores**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMjEFZDwLbKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from heapq import nlargest"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwa0BaGKLf7B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0192a8d0-7289-4f33-dfe0-e84e4f628c24"
      },
      "source": [
        "select_length = int(len(sentence_tokens)*0.3) # 0.3 ----> 30% percent sentences\n",
        "select_length"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyDMuPzBLwAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# 30% summary is\n",
        "\n",
        "summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNbSMnBmMDsy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "0b450eb1-07ec-4891-e452-28068c0726dc"
      },
      "source": [
        "summary"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[We may get the facilities of topic modeling and word embedding in other packages like ‘scikit-learn’ and ‘R’, but the facilities provided by Gensim for building topic models and word embedding is unparalleled.,\n",
              " In order to speed up processing and retrieval on machine clusters, Gensim provides efficient multicore implementations of various popular algorithms like Latent Semantic Analysis (LSA), Latent Dirichlet Allocation (LDA), Random Projections (RP), Hierarchical Dirichlet Process (HDP).\n",
              " ,\n",
              " Apart from performing the above complex tasks, Gensim, implemented in Python and Cython, is designed to handle large text collections using data streaming as well as incremental online algorithms.,\n",
              " As we know that Python is a very versatile language as being pure Python Gensim runs on all the platforms (like Windows, Mac OS, Linux) that supports Python and Numpy.\n",
              " ,\n",
              " fastText\n",
              " fastText, uses a neural network for word embedding, is a library for learning of word embedding and text classification.,\n",
              " Gensim doesn’t require costly annotations or hand tagging of documents because it uses unsupervised models.,\n",
              " Another most significant advantage of Gensim is that, it let us handle large text files even without loading the whole file in memory.\n",
              " ,\n",
              " Gensim can easily process large and web-scale corpora by using its incremental online training algorithms.,\n",
              " “Generate Similar” is a popular open source natural language processing (NLP) library used for unsupervised topic modeling.,\n",
              " Gensim is licensed under the OSI-approved GNU LGPL license which allows it to be used for both personal as well as commercial use for free.,\n",
              " In 2008, Gensim started off as a collection of various Python scripts for the Czech Digital Mathematics.,\n",
              " Any modifications made in Gensim are in turn open-sourced and has abundance of community support too.\n",
              " ,\n",
              " Gensim is a NLP package that does topic modeling.,\n",
              " Gensim is robust in nature and has been in use in various systems by various people as well as organisations for over 4 years.,\n",
              " It is a technique in NLP (Natural Language Processing) that allows us to analyse relationships between a set of documents and their containing terms.,\n",
              " Following are some of the features and capabilities offered by Gensim −\n",
              " \n",
              " Scalability,\n",
              " Gensim has been used and cited in over thousand commercial and academic applications.]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2j62neFOtpk",
        "colab_type": "text"
      },
      "source": [
        "#**Use 10% percent and see the results thank you good luck!!!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-f8prYkMFgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use 10% percent and see the results"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}